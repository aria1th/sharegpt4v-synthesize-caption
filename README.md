# sharegpt4v-colab
 ShareGPT4V Captioning for Colab

[google colaboratory link](https://colab.research.google.com/drive/1Dn7aW4TzzihiHyINRk6_pCrpy0vEH_mg?usp=sharing)https://colab.research.google.com/drive/1Dn7aW4TzzihiHyINRk6_pCrpy0vEH_mg?usp=sharing

[Updated link](https://colab.research.google.com/drive/1ekKNzLH5fAkZQG0HU_VN35uQyswPGP7v?usp=sharing)
You can use either API or gradio / code for inference.

# Inputs
You can use Image URL(RAW, should specify header) / Base64 String / File path.

You can use Text URL(RAW) / File path / Raw text. We expect comma-separated caption, from Danbooru / Pixiv / or some dedicated human annotated source.

# Colab
This colab will setup venv, download llama and model, then run the gradio app with public API / or local address, with default auth. 

![image](https://github.com/aria1th/sharegpt4v-synthesize-caption/assets/35677394/de033c95-6118-4208-bf7d-5aea8a313811)

![image](https://github.com/aria1th/sharegpt4v-synthesize-caption/assets/35677394/3bc58140-a8e4-49c8-9bd8-78830793f3c9)

Visit <URL>/docs for API usage.

